# =============================================================================
# ENVIRONMENT CONFIGURATION TEMPLATE
# =============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control - it contains sensitive credentials
# =============================================================================

# -----------------------------------------------------------------------------
# API Keys & Authentication
# -----------------------------------------------------------------------------

# OpenRouter API Key for AI Analysis
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# HuggingFace API Token for model rankings/benchmarks
# Get your token at: https://huggingface.co/settings/tokens
HF_TOKEN=your_huggingface_token_here

# Web Application API Key (for internal API authentication)
# Generate a secure random string (e.g., using: python -c "import secrets; print(secrets.token_urlsafe(64))")
API_KEY_FOR_APP=your_secure_api_key_here

# Flask Secret Key (required for sessions, CSRF protection)
# Generate a secure random string (e.g., using: python -c "import secrets; print(secrets.token_hex(32))")
SECRET_KEY=your_secret_key_here

# -----------------------------------------------------------------------------
# Database Configuration
# -----------------------------------------------------------------------------

# SQLite (default for development)
DATABASE_URL=sqlite:///instance/app.db

# PostgreSQL (recommended for production)
# DATABASE_URL=postgresql://username:password@localhost:5432/dbname

# -----------------------------------------------------------------------------
# Redis Configuration (for Celery task queue)
# -----------------------------------------------------------------------------

REDIS_URL=redis://localhost:6379/0

# -----------------------------------------------------------------------------
# Task Orchestration & Distributed Execution
# -----------------------------------------------------------------------------

# Enable Celery distributed task execution (requires Redis + Celery worker)
# When true, analysis tasks are dispatched to Celery workers via Redis message queue
# When false, tasks execute in-process using ThreadPoolExecutor (limited concurrency)
# NOTE: start.ps1 automatically starts Redis and Celery worker containers
USE_CELERY_ANALYSIS=true

# Celery broker and result backend URLs
# Must match REDIS_URL unless using separate Redis instances
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Enable Pipeline Execution Service (background daemon for pipeline orchestration)
# Should be true in celery-worker container, false in web container
# This prevents race conditions from multiple processes polling the same pipeline
# In Docker: web=false, celery-worker=true (see docker-compose.yml)
# In local dev: true (only one process)
ENABLE_PIPELINE_SERVICE=true

# Pipeline Analysis Mode (per-pipeline config, not global env var)
# ------------------------------------------------------------------
# Pipeline config supports two analysis execution modes:
#
# 1. STREAMING MODE (default, recommended):
#    - Analyzes each app IMMEDIATELY after it's generated
#    - Better resource utilization (no idle waiting)
#    - Faster overall pipeline execution (pipelined, not waterfall)
#    - Config: {"analysis": {"options": {"streamingAnalysis": true}}}
#
# 2. BATCH MODE (legacy, backward compatibility):
#    - Waits for ALL apps to generate before starting ANY analysis
#    - Sequential waterfall pattern (generate all â†’ analyze all)
#    - Useful for debugging or when analysis depends on all apps being ready
#    - Config: {"analysis": {"options": {"streamingAnalysis": false}}}
#
# The mode is set per-pipeline in the automation wizard UI, not via environment variable.
# Default is streaming mode for optimal performance.

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------

# Flask environment (development, production, testing)
FLASK_ENV=development

# Enable debug mode (NEVER enable in production)
FLASK_DEBUG=true

# Application host and port
FLASK_HOST=0.0.0.0
FLASK_PORT=5000

# -----------------------------------------------------------------------------
# Feature Flags
# -----------------------------------------------------------------------------

# Enable analyzer functionality (requires Docker)
ANALYZER_ENABLED=true

# Enable user registration
REGISTRATION_ENABLED=true

# Enable CSRF protection (should be true in production)
WTF_CSRF_ENABLED=false

# -----------------------------------------------------------------------------
# Docker & Analyzer Configuration
# -----------------------------------------------------------------------------

# Docker host (leave empty to use default)
DOCKER_HOST=

# Analyzer service ports (if using custom ports)
# ANALYZER_PORT_START=2001
# ANALYZER_PORT_END=2004

# -----------------------------------------------------------------------------
# AI Analyzer Settings (cost control)
# -----------------------------------------------------------------------------

# Default OpenRouter model for AI analyzer
AI_MODEL=google/gemini-2.5-flash

# Batch mode reduces API calls (true recommended)
AI_BATCH_MODE=true

# Optimized mode scans only LLM-generated files (true recommended)
AI_OPTIMIZED_MODE=true

# Max code chars included per request
AI_CODE_TRUNCATION_LIMIT=30000

# Response token limits
AI_MAX_RESPONSE_TOKENS=300
AI_BATCH_MAX_TOKENS=1500

# Disable expensive code-quality analyzer by default
AI_QUALITY_ANALYZER_ENABLED=false

# AI Analyzer Resilience Settings
# --------------------------------
# Maximum number of retries for API calls (default: 3)
AI_MAX_RETRIES=3

# Base delay in seconds for exponential backoff (default: 2.0)
AI_BASE_RETRY_DELAY=2.0

# Maximum delay between retries in seconds (default: 30.0)
AI_MAX_RETRY_DELAY=30.0

# API timeout for single requirement analysis in seconds (default: 60)
AI_TIMEOUT_SINGLE=60

# API timeout for batch analysis in seconds (default: 120)
AI_TIMEOUT_BATCH=120

# API timeout for quality analysis in seconds (default: 90)
AI_TIMEOUT_QUALITY=90

# -----------------------------------------------------------------------------
# Circuit Breaker Configuration
# -----------------------------------------------------------------------------

# Number of consecutive failures before service is temporarily disabled (default: 5)
CIRCUIT_BREAKER_THRESHOLD=5

# Cooldown period in seconds after circuit breaker trips (default: 120)
CIRCUIT_BREAKER_COOLDOWN=120.0

# Maximum retries for transient service failures (default: 3)
TRANSIENT_FAILURE_MAX_RETRIES=3

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log file path
LOG_FILE=logs/app.log

# -----------------------------------------------------------------------------
# Email Configuration (if needed for notifications)
# -----------------------------------------------------------------------------

# SMTP server settings
# MAIL_SERVER=smtp.gmail.com
# MAIL_PORT=587
# MAIL_USE_TLS=true
# MAIL_USERNAME=your_email@example.com
# MAIL_PASSWORD=your_email_password

# -----------------------------------------------------------------------------
# Additional Configuration
# -----------------------------------------------------------------------------

# Any additional environment variables your application needs
