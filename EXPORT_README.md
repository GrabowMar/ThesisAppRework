# Thesis Research Data Export

## Overview
This export contains the complete dataset from the thesis research platform, including both analysis results and generated application source code.

**Export Details:**
- **File:** `thesis_export_20260120_072049.zip`
- **Size:** 9.82 MB compressed
- **Total Files:** 2,247 files
- **Export Date:** 2026-01-20 07:20:51 UTC
- **Version:** 1.0

## Contents

### Analysis Results (147 files)
Analysis results from pipeline executions, including:
- Security analysis (Bandit, Semgrep, ESLint, etc.)
- Performance testing (Locust, Apache Bench)
- Dynamic analysis (ZAP, endpoint testing)
- AI-powered code quality analysis
- SARIF formatted reports
- Result manifests and metadata

**Models with Analysis Results:**
- `deepseek_deepseek-r1-0528`: 60 files
- `google_gemini-2.5-flash`: 51 files
- `qwen_qwen3-coder-30b-a3b-instruct`: 36 files

### Generated Applications (2,100 files)
Complete source code for AI-generated web applications across multiple models:

| Model | Apps | Files |
|-------|------|-------|
| qwen_qwen3-coder-30b-a3b-instruct | 23 | 460 |
| deepseek_deepseek-r1-0528 | 20 | 400 |
| google_gemini-2.5-flash | 20 | 400 |
| anthropic_claude-4.5-sonnet-20250929 | 10 | 200 |
| anthropic_claude-sonnet-4.5 | 10 | 200 |
| openai_gpt-5-mini-2025-08-07 | 10 | 200 |
| openai_gpt-5-mini | 10 | 200 |
| openai_gpt-4o-mini | 2 | 40 |

**Total:** 105 applications generated across 7 AI models

## File Structure

```
thesis_export_20260120_072049.zip
├── export_metadata.json              # Export metadata and statistics
├── results/                           # Analysis results
│   └── {model_slug}/
│       └── app{N}/
│           └── task_{task_id}/
│               ├── manifest.json      # Task metadata
│               ├── {result}.json      # Unified analysis results
│               ├── services/          # Individual service results
│               └── sarif/             # SARIF formatted reports
└── generated/apps/                    # Generated application source code
    └── {model_slug}/
        └── app{N}/
            ├── docker-compose.yml     # Docker orchestration
            ├── README.md              # App documentation
            ├── .env                   # Environment variables
            ├── frontend/              # Frontend code
            │   ├── Dockerfile
            │   ├── package.json
            │   └── src/
            └── backend/               # Backend code
                ├── Dockerfile
                ├── requirements.txt
                └── app/
```

## Import Instructions

### Using the Web UI
1. Navigate to **Automation Pipeline** page
2. Find **Results Management** card in the sidebar
3. Click **Import** button
4. Upload the ZIP file
5. Configure options:
   - ☑ **Create backup before import** (recommended)
   - ☐ Overwrite existing results (if needed)
6. Click **Import** to restore data

### Using Python Script
```python
import zipfile
from pathlib import Path

# Extract to project root
with zipfile.ZipFile('thesis_export_20260120_072049.zip', 'r') as zipf:
    zipf.extractall('/path/to/thesisapp')
```

### Manual Extraction
```bash
cd /path/to/thesisapp
unzip thesis_export_20260120_072049.zip
```

## Backups Created

The following backups were created before export:
- `results_backup_20260120_070406.tar.gz` (7.6 MB) - Original results directory

## Data Filtering

This export includes:
- ✓ Analysis results from all models
- ✓ Generated app source code from all models
- ✓ Export metadata and statistics
- ✗ Node modules (excluded to reduce size)
- ✗ Python virtual environments (excluded)
- ✗ Cache directories (excluded)

## Excluded Directories (for Size Optimization)
To keep the export size manageable, the following directories were excluded from generated apps:
- `node_modules/`
- `.venv/`, `venv/`
- `__pycache__/`
- `.git/`
- `.mypy_cache/`, `.pytest_cache/`
- `dist/`, `build/`, `.eggs/`

These can be regenerated by running:
- Frontend: `npm install`
- Backend: `pip install -r requirements.txt`

## Metadata Schema

The `export_metadata.json` file contains:
```json
{
  "export_timestamp": "2026-01-20T07:20:51.754522",
  "export_version": "1.0",
  "statistics": {
    "total_files": 2247,
    "results_files": 147,
    "apps_files": 2100
  }
}
```

## Use Cases

### Backup & Recovery
Keep this export as a backup of your thesis research data. Can be imported to restore the complete dataset.

### Data Transfer
Transfer research data between environments or share with collaborators. The ZIP format ensures portability.

### Archival
Long-term archival of research results for reproducibility and future analysis.

### Migration
Move data to a new installation of the thesis research platform.

## Verification

To verify the export integrity:
```bash
# Check file count
unzip -l thesis_export_20260120_072049.zip | wc -l

# Verify metadata
unzip -p thesis_export_20260120_072049.zip export_metadata.json

# Test extraction
unzip -t thesis_export_20260120_072049.zip
```

## Support

For issues with import/export:
1. Check that the ZIP file is not corrupted
2. Verify sufficient disk space for extraction
3. Ensure proper file permissions
4. Check application logs at `src/logs/` for detailed error messages

## Technical Details

**Export Implementation:**
- Format: ZIP (DEFLATED compression)
- Python implementation using `zipfile` module
- Preserves directory structure and file permissions
- Automatic backup creation before import
- Conflict detection and resolution options

**API Endpoints:**
- `POST /api/automation/results/export` - Export data
- `POST /api/automation/results/import` - Import data

**Web UI Location:**
- Automation Pipeline page → Results Management sidebar card

---

**Generated:** 2026-01-20
**Platform:** ThesisAppRework - AI Code Generation Analysis Platform
**Export Version:** 1.0
